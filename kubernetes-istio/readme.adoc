= Istio

== Introduction

Istio can be use for :

* Traffic managment

** Circuit Breaker
** Timeout
** Retries
** A/B Testing
** Canary Rollouts
** Stages rollouts with % Based

* Security

** Secure communication channel
** Manage authentication
** Authorization
** Encryption of service communication

Security use (Service-Service) or (Pod-Pod)

* Policies

** Rate limit
** Restrict acces
** Header rewrite and redirect

* Observability

** Tracing
** Monitoring
** Logging

== Traffic Managment

=== VirtualService Api ojbect

VirtualService is used to define routing rules in the service mesh. We will use
virtual services to describe how to route incoming traffic from an Istio gateway to
the Kubernetes services and between services. We will also use virtual services to
inject faults and delays in order to test the reliability and resilience capabilities of
the service mesh.


Exemple :


[source, yml]
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    route:
    - destination:
        host: reviews
        subset: v2
  - route:
    - destination:
        host: reviews
        subset: v3
----


=== Destination rules

DestinationRule is used to define policies and rules for traffic that is routed
(using a virtual service) to a specific service (that is, a destination). We will use
destination rules to set up encryption policies to encrypt internal HTTP traffic
and define service subsets that describe available versions of the services. We
will use service subsets when performing zero downtime (blue/green)
deployments from an existing version of a microservice to a new version.



Exemple :


[source, yml]
----
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: my-destination-rule
spec:
  host: my-svc
  trafficPolicy:
    loadBalancer:
      simple: RANDOM
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN
  - name: v3
    labels:
      version: v3


----

=== Gateways

Gateway is used to configure how to handle incoming traffic to, and outgoing
traffic from, the service mesh. A gateway depends on a virtual service routing the
incoming traffic to Kubernetes services. We will use a gateway object to accept
incoming traffic to the DNS name, minikube.me , using HTTPS. Refer to the
Kubernetes Ingress resource replaced with Istio Ingress Gateway as an edge
server section for details.

Exemple :


[source, yml]
----
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ext-host-gwy
spec:
  selector:
    app: my-gateway-controller
  servers:
  - port:
      number: 443
      name: https
      protocol: HTTPS
    hosts:
    - ext-host.example.com
    tls:
      mode: SIMPLE
      serverCertificate: /tmp/tls.crt
      privateKey: /tmp/tls.key
----

=== Service entries

You use a service entry to add an entry to the service registry that Istio maintains internally. After you add the service entry, the Envoy proxies can send traffic to the service as if it was a service in your mesh. Configuring service entries allows you to manage traffic for services running outside of the mesh, including the following tasks:

* Redirect and forward traffic for external destinations, such as APIs consumed from the web, or traffic to services in legacy infrastructure.
* Define retry, timeout, and fault injection policies for external destinations.
* Run a mesh service in a Virtual Machine (VM) by adding VMs to your mesh.
* Logically add services from a different cluster to the mesh to configure a multicluster Istio mesh on Kubernetes.

You don’t need to add a service entry for every external service that you want your mesh services to use. By default, Istio configures the Envoy proxies to passthrough requests to unknown services. However, you can’t use Istio features to control the traffic to destinations that aren’t registered in the mesh.



[source, yml]
----

apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: svc-entry
spec:
  hosts:
  - ext-svc.example.com
  ports:
  - number: 443
    name: https
    protocol: HTTPS
  location: MESH_EXTERNAL
  resolution: DNS


----

== Security

Security in Istio involves multiple components:

* Citadel for key and certificate management
* Sidecar and perimeter proxies to implement secure communication between clients and servers
* Pilot to distribute authentication policies and secure naming information to the proxies
* Mixer: consists of two different runtime components:
** Policy : enforces network policies such as authentication,
authorization, rate limits, and quotas.
** Telemetry : collects telemetry information and sends it to
Prometheus, for example.


image::policies.png[]

== Policies

Policy is used to define how requests will be authenticated. We will use policies
to require incoming requests to the service mesh to be authenticated using a
JWT-based OAuth 2.0/OIDC access token. Refer to the Authenticating external
requests using OAuth 2.0/OIDC access tokens section of this chapter. A policy can
also be used to define how to secure parts of the internal communication in the
service mesh. For example, a policy can require that internal requests are
encrypted using HTTPS or allow plain text requests. Finally,
a MeshPolicy object can be used to define global policies that apply to the whole
service mesh.


== Observabilies


=== Metrics

=== Logs

=== Distributed tracing

=== Visualizing Your Mesh

=== Remotely Accessing Telemetry Addons






== Introducing runtime components in Istio


* Galley: responsible for collecting and validating configuration information and
distribution to the other Istio components in the control plane.


* Kiali: provides observability to the service mesh, visualizing what is going on in
the mesh. Kiali is a separate open source project (see https://www.kiali.io )
Prometheus: performs data ingestion and storage for time series-based data, for
example, performance metrics.

* Prometheus is a separate open source project (refer to https://prometheus.io ).

* Grafana: visualizes performance metrics and other time series-related data
collected in Prometheus. Grafana is a separate open source project (see https://grafana.com ).

* Tracing: handles and visualizes distributed tracing information. Based on Jaeger,
it is an open source project for distributed tracing (refer to https://www.jaegertracing.io ).


The Istio data plane consists of the following runtime components:

* Ingress Gateway: handles incoming traffic to the service mesh
* Egress Gateway: handles outgoing traffic from the service mesh
* All pods with an Istio proxy are injected as a sidecar
The runtime components in Istio's control plane and data plane are summarized in the
following diagram:

image::istio-1.png[]



== Deploying Istio in a Kubernetes cluster

https://istio.io/docs/setup/install/


=== Profiles Istio

|===
|  |default |demo |minimal |sds| remote

| Core components
|
|
|
|
|


| istio-citadel
| X
| X
| X
| X
|

| istio-egressgateway
|
| X
|
|
|

| istio-galley
| X
| X
|
| X
|

| istio-ingressgateway
| X
| X
|
| X
|

| istio-nodeagent
|
|
|
| X
|

| istio-pilot
| X
| X
| X
| X
|

| istio-policy
| X
| X
|
| X
|

| istio-sidecar-injector
| X
| X
|
| X
| X


| istio-telemetry
| X
| X
|
| X
|



| Addons
|
|
|
|
|


| grafana
|
| X
|
|
|


| istio-tracing
|
| X
|
|
|

| kiali
|
| X
|
|
|

| prometheus
| X
| X
|
| X
|


|===

=== Install Istio using the default profile

[source,]
----
istioctl manifest apply
----


=== install demo profile or other profile

[source,]
----
istioctl manifest apply --set profile=demo
----


=== Display the list of available profiles

[source,]
----
istioctl profile list
----

=== Display the configuration of a profile

[source,]
----
istioctl profile dump demo
istioctl profile dump --config-path trafficManagement.components.pilot demo
----

=== Show differences in profiles

[source,]
----
istioctl profile dump default > 1.yaml
istioctl profile dump demo > 2.yaml
istioctl profile diff 1.yaml 2.yaml
----


=== Verify a successful installation

[source,]
----
istioctl verify-install -f $HOME/generated-manifest.yaml
----


=== Kiali's config

[source,]
----
kubectl -n istio-system apply -f kubernetes-istio/istio/setup/kiali-configmap.yml && \
kubectl -n istio-system delete pod -l app=kiali && \
kubectl -n istio-system wait --timeout=60s --for=condition=ready pod -l app=kiali
----


=== Kiali witj jaeger

[source,]
----
kubectl port-forward -n istio-system $(kubectl get pod -n istio-system -l app=jaeger -o jsonpath='{.items[0].metadata.name}') 16686:16686&
istioctl dashboard kiali
----

=== Kiali

[source,]
----
kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=kiali -o jsonpath='{.items[0].metadata.name}') 20001:20001
----
ou

[source,]
----
istioctl dashboard kiali
----

=== Grafana Dashboard

[source,]
----
kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath='{.items[0].metadata.name}') 3000:3000
----
ou
[source,]
----
istioctl dashboard grafana
----


=== Prometheus Dashboard

[source,]
----
kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=prometheus -o jsonpath='{.items[0].metadata.name}') 9090:9090
----
ou
[source,]
----
istioctl dashboard prometheus
----

=== Jaeger Dashboard

[source,]
----
kubectl port-forward -n istio-system $(kubectl get pod -n istio-system -l app=jaeger -o jsonpath='{.items[0].metadata.name}') 16686:16686
----
ou
[source,]
----
istioctl dashboard jaeger
----

=== istioctl dashboard

[source,]
----
 istioctl dashboard [command]
----

Available Commands:

* controlz    -> Open ControlZ web UI
* envoy       -> Open Envoy admin web UI
* grafana     -> Open Grafana web UI
* jaeger      -> Open Jaeger web UI
* kiali       -> Open Kiali web UI
* prometheus  -> Open Prometheus web UI
* zipkin      -> Open Zipkin web UI



== Run dev mode

=== Perform the following steps to set up the Minikube tunnel

[source,]
----
minikube tunnel
INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
echo "$INGRESS_HOST minikube.me" | sudo tee -a /etc/hosts
----


[source,]
----
eval $(minikube docker-env)

kubectl delete namespace hands-on
kubectl create namespace hands-on
kubectl config set-context $(kubectl config current-context) --namespace=hands-on

./kubernetes-istio/scripts/deploy-dev-env.bash
----

=== Test dev mode

[source,]
----
PRODUCT_COMPOSITE_HOST=$( kubectl -n hands-on get service product-composite -o jsonpath='{.spec.clusterIP}')
HOST=minikube.me PORT=443  HEALTH_URL=http://${PRODUCT_COMPOSITE_HOST}:4004  MGM_PORT=4004 local/test-em-all.bash
----


=== DO TRAFFICS

[source,]
----
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d grant_type=password -d username=dkahn -d password=password -s | jq .access_token -r)
siege https://minikube.me/product-composite/2 -H "Authorization: Bearer $ACCESS_TOKEN" -c1 -d1
----


== Ensuring that a service mesh is resilient

=== Testing resilience by injecting faults

[source,yml]
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: product-vs
spec:
  hosts:
    - product
  http:
  - route:
    - destination:
        host: product
    fault:
      abort:
        httpStatus: 500
        percent: 20
----

=== Testing resilience by injecting delays


[source,yml]
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: product-vs
spec:
  hosts:
    - product
  http:
  - route:
    - destination:
        host: product
    fault:
      delay:
        fixedDelay: 3s
        percent: 100

----

To test :

[source,]
----
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d grant_type=password -d username=dkahn -d password=password -s | jq .access_token -r)
for i in {1..6}; do time curl -k https://minikube.me/product-composite/2 -H "Authorization: Bearer $ACCESS_TOKEN"; done
----





== Running commands for prod and testing


=== Perform the following steps to set up the Minikube tunnel

[source,]
----
minikube tunnel
INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
echo "$INGRESS_HOST minikube.me" | sudo tee -a /etc/hosts
----


[source,]
----
eval $(minikube docker-env)

kubectl delete namespace hands-on
kubectl create namespace hands-on
kubectl config set-context $(kubectl config current-context) --namespace=hands-on

./kubernetes-istio/scripts/deploy-dev-env.bash
----


=== Test prod mode

[source,]
----
PRODUCT_COMPOSITE_HOST=$( kubectl -n hands-on get service product-composite -o jsonpath='{.spec.clusterIP}')
SKIP_CB_TESTS=true HOST=minikube.me PORT=443  HEALTH_URL=http://${PRODUCT_COMPOSITE_HOST}:4004  MGM_PORT=4004 local/test-em-all.bash
----


=== Running canary tests


[source,]
----
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d grant_type=password -d username=dkahn -d password=password -s | jq .access_token -r)
curl -ks https://minikube.me/product-composite/2 -H "Authorization: Bearer $ACCESS_TOKEN" | jq .serviceAddresses
curl -ks https://minikube.me/product-composite/2 -H "Authorization: Bearer $ACCESS_TOKEN" -H "X-group: test" | jq .serviceAddresses
----

=== Running blue/green tests


[source,]
----
kubectl patch virtualservice product-composite-vs --type=json -p='[
  {"op": "add", "path": "/spec/http/0/route/0/weight", "value": 100},
  {"op": "add", "path": "/spec/http/0/route/1/weight", "value": 0}
]'
----